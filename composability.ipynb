{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81ab12d-6512-4c27-8b82-9e12dec6d4d6",
   "metadata": {},
   "source": [
    "# Composability\n",
    "\n",
    "This notebook shows off some basic functionality around LangChain Expression Language, which makes it really easy to compose arbitrary chains.\n",
    "\n",
    "For a much deeper dive, see:\n",
    "\n",
    "- [Full LangChain Expression Language Documentation](https://python.langchain.com/docs/expression_language/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b9f0ca",
   "metadata": {},
   "source": [
    "## Basic Composability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "504f9999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import openai\n",
    "\n",
    "dotenv_path = Path('./.env')\n",
    "load_dotenv(dotenv_path=dotenv_path)  # add your GOOGLE API key here\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "openai.api_key = os.getenv(\"OPEN_AI_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPEN_AI_KEY\")\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c629ae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "# model = ChatOpenAI(api_key=os.getenv(\"OPEN_AI_KEY\"))\n",
    "model = ChatOpenAI()\n",
    "googlellm  = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47e25734",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | output_parser\n",
    "chain2 = prompt | googlellm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b97b0fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't bears wear shoes?\\n\\nBecause they have bear feet!\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0718ab92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why did the bear get kicked out of the restaurant?\\n\\nBecause he wasn't wearing pants!\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1391ac95",
   "metadata": {},
   "source": [
    "### Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edaab49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Why don't bears wear shoes?\\n\\nBecause they have bear feet!\",\n",
       " 'Why don\\'t clowns like talking on the phone?\\n\\nBecause it always involves a lot of \"ring-a-ling\"!']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{\"topic\": \"bear\"}, {\"topic\": \"clowns\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec25b6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Why did the bear get kicked out of the restaurant?\\n\\nBecause he ate the waiter's tips.\",\n",
       " \"Why don't pirates eat gold for breakfast?\\n\\nBecause it’s too “coin”cidental.\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2.batch([{\"topic\": \"bear\"}, {\"topic\": \"gold\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2074e242",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c29b910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Why\n",
      " don\n",
      "'t\n",
      " bears\n",
      " wear\n",
      " shoes\n",
      "?\n",
      "\n",
      "\n",
      "Because\n",
      " they\n",
      " have\n",
      " bear\n",
      " feet\n",
      "!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"topic\": \"bears\"}):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af5d418e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the bear go to the doctor?\n",
      "Because he wasn't feeling\n",
      " berry well.\n"
     ]
    }
   ],
   "source": [
    "for s in chain2.stream({\"topic\": \"bears\"}):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa5be86",
   "metadata": {},
   "source": [
    "## RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0ed6b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers.tavily_search_api import TavilySearchAPIRetriever\n",
    "\n",
    "retriever= TavilySearchAPIRetriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the question based only on the context provided:\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94e75648",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | output_parser\n",
    "chain2 = prompt | googlellm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abcbf78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith is a testing and observability platform developed by the Langchain team.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what is langsmith\"\n",
    "context = \"langsmith is a testing and observability platform built by the langchain team\"\n",
    "chain.invoke({\"question\": question, \"context\": context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac0b0d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A testing and observability platform built by the langchain team'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2.invoke({\"question\": question, \"context\": context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98b8a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "retrieval_chain = RunnablePassthrough.assign(\n",
    "    context=(lambda x: x[\"question\"]) | retriever\n",
    ") | chain\n",
    "\n",
    "retrieval_chain2 = RunnablePassthrough.assign(\n",
    "    context=(lambda x: x[\"question\"]) | retriever\n",
    ") | chain2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c488db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents, assisting in moving from prototype to production. It provides features such as debugging, testing, and monitoring chains and agents built on any LLM framework, and integrates seamlessly with LangChain.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain.invoke({\"question\": \"what is langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57569564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents to move from prototype to production.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain2.invoke({\"question\": \"what is langsmith\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5cff2b",
   "metadata": {},
   "source": [
    "## RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b36365f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d2ca55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"{question}\"\"\")\n",
    "simple_chain = prompt | model | output_parser\n",
    "simple_chain2 = prompt | googlellm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2e2db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain = RunnableParallel({\n",
    "    \"retrieved_answer\": retrieval_chain,\n",
    "    \"simple_answer\": simple_chain\n",
    "})\n",
    "\n",
    "parallel_chain2 = RunnableParallel({\n",
    "    \"retrieved_answer\": retrieval_chain2,\n",
    "    \"simple_answer\": simple_chain2\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "21db1151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents, allowing developers to move from prototype to production. It provides tools for debugging, testing, evaluating, and monitoring chains and agents built on any language model (LLM) framework. It seamlessly integrates with LangChain, an open-source framework for building with LLMs.',\n",
       " 'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith\". It might be a misspelling or a lesser-known term. Can you please provide more context or clarify your question?'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_chain.invoke({\"question\": \"what is langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b8c92f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'retrieved_answer': 'LangSmith is a unified platform for debugging, testing, evaluating, and monitoring chains and intelligent agents built on any LLM framework. It seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.',\n",
       " 'simple_answer': \"Langsmith is a language learning platform that aims to make language learning more fun and engaging. It offers a variety of courses in different languages, as well as games, quizzes, and other activities to help learners stay motivated and engaged.\\n\\nLangsmith uses a variety of teaching methods to cater to different learning styles. These methods include:\\n\\n* **Interactive lessons:** Langsmith's lessons are interactive and engaging, with a variety of activities to keep learners entertained and motivated.\\n* **Games and quizzes:** Langsmith offers a variety of games and quizzes to help learners practice their language skills in a fun and engaging way.\\n* **Real-world content:** Langsmith's lessons and activities are based on real-world content, so learners can learn the language as it is actually used.\\n* **Community:** Langsmith has a community of learners who can help each other out and share their language learning experiences.\\n\\nLangsmith is available on a variety of devices, including computers, smartphones, and tablets. This makes it easy for learners to learn a language at their own pace and on their own schedule.\\n\\nOverall, Langsmith is a well-rounded language learning platform that offers a variety of features and activities to help learners stay motivated and engaged. It is a good option for learners of all levels who are looking for a fun and effective way to learn a new language.\\n\\nHere are some of the benefits of using Langsmith:\\n\\n* **It is fun and engaging.** Langsmith's lessons and activities are designed to be fun and engaging, so learners are more likely to stick with it.\\n* **It is effective.** Langsmith's teaching methods are based on sound pedagogical principles, so learners can be sure that they are learning the language correctly.\\n* **It is flexible.** Langsmith is available on a variety of devices, so learners can learn a language at their own pace and on their own schedule.\\n* **It is affordable.** Langsmith offers a variety of subscription plans to fit different budgets.\\n\\nIf you are looking for a fun and effective way to learn a new language, Langsmith is a great option.\"}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_chain2.invoke({\"question\": \"what is langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39a00772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'simple_answer': ''}\n",
      "{'simple_answer': 'There'}\n",
      "{'simple_answer': ' is'}\n",
      "{'simple_answer': ' no'}\n",
      "{'simple_answer': ' widely'}\n",
      "{'simple_answer': ' recognized'}\n",
      "{'simple_answer': ' term'}\n",
      "{'simple_answer': ' or'}\n",
      "{'simple_answer': ' definition'}\n",
      "{'simple_answer': ' for'}\n",
      "{'simple_answer': ' \"'}\n",
      "{'simple_answer': 'lang'}\n",
      "{'simple_answer': 'smith'}\n",
      "{'simple_answer': '.\"'}\n",
      "{'simple_answer': ' It'}\n",
      "{'simple_answer': ' could'}\n",
      "{'simple_answer': ' potentially'}\n",
      "{'simple_answer': ' be'}\n",
      "{'simple_answer': ' a'}\n",
      "{'simple_answer': ' proper'}\n",
      "{'simple_answer': ' noun'}\n",
      "{'simple_answer': ' referring'}\n",
      "{'simple_answer': ' to'}\n",
      "{'simple_answer': ' a'}\n",
      "{'simple_answer': ' specific'}\n",
      "{'simple_answer': ' person'}\n",
      "{'simple_answer': ' or'}\n",
      "{'simple_answer': ' entity'}\n",
      "{'simple_answer': '.'}\n",
      "{'simple_answer': ' Without'}\n",
      "{'simple_answer': ' further'}\n",
      "{'simple_answer': ' context'}\n",
      "{'simple_answer': ' or'}\n",
      "{'simple_answer': ' information'}\n",
      "{'simple_answer': ','}\n",
      "{'simple_answer': ' it'}\n",
      "{'simple_answer': ' is'}\n",
      "{'simple_answer': ' difficult'}\n",
      "{'simple_answer': ' to'}\n",
      "{'simple_answer': ' provide'}\n",
      "{'simple_answer': ' an'}\n",
      "{'simple_answer': ' accurate'}\n",
      "{'simple_answer': ' answer'}\n",
      "{'simple_answer': '.'}\n",
      "{'simple_answer': ''}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection error caused failure to post https://api.smith.langchain.com/runs  in LangSmith API. Please confirm your LANGCHAIN_ENDPOINT. ConnectTimeout(MaxRetryError(\"HTTPSConnectionPool(host='api.smith.langchain.com', port=443): Max retries exceeded with url: /runs (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x1486eae90>, 'Connection to api.smith.langchain.com timed out. (connect timeout=7.0)'))\"))\n",
      "Connection error caused failure to patch https://api.smith.langchain.com/runs/02c8b2ac-23cd-47c8-8473-67faa7413c58  in LangSmith API. Please confirm your LANGCHAIN_ENDPOINT. ConnectionError(MaxRetryError('HTTPSConnectionPool(host=\\'api.smith.langchain.com\\', port=443): Max retries exceeded with url: /runs/02c8b2ac-23cd-47c8-8473-67faa7413c58 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host=\\'api.smith.langchain.com\\', port=443): Read timed out. (read timeout=7.0)\"))'))\n"
     ]
    },
    {
     "ename": "ReadTimeout",
     "evalue": "HTTPSConnectionPool(host='api.tavily.com', port=443): Read timed out. (read timeout=100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/urllib3/connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTimeoutError\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:844\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    842\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 844\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/urllib3/util/retry.py:470\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 470\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/urllib3/util/util.py:39\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:538\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 538\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:370\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[0;32m--> 370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='api.tavily.com', port=443): Read timed out. (read timeout=100)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m parallel_chain\u001b[38;5;241m.\u001b[39mstream({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is langsmith\u001b[39m\u001b[38;5;124m\"\u001b[39m}):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(s)\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2450\u001b[0m, in \u001b[0;36mRunnableParallel.stream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[1;32m   2445\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2446\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   2447\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2448\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2449\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m-> 2450\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config)\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2440\u001b[0m, in \u001b[0;36mRunnableParallel.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   2435\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2436\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   2437\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2438\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   2439\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m-> 2440\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[1;32m   2441\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   2442\u001b[0m     )\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1226\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1225\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1226\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   1228\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2425\u001b[0m, in \u001b[0;36mRunnableParallel._transform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2423\u001b[0m (step_name, generator) \u001b[38;5;241m=\u001b[39m futures\u001b[38;5;241m.\u001b[39mpop(future)\n\u001b[1;32m   2424\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2425\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m AddableDict({step_name: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m})\n\u001b[1;32m   2426\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   2427\u001b[0m     futures[executor\u001b[38;5;241m.\u001b[39msubmit(\u001b[38;5;28mnext\u001b[39m, generator)] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2428\u001b[0m         step_name,\n\u001b[1;32m   2429\u001b[0m         generator,\n\u001b[1;32m   2430\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2132\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   2127\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2128\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   2129\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2130\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2131\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 2132\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[1;32m   2133\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[1;32m   2135\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m   2136\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2137\u001b[0m     )\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1226\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1225\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1226\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   1228\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2096\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2087\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[1;32m   2088\u001b[0m     final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   2089\u001b[0m         final_pipeline,\n\u001b[1;32m   2090\u001b[0m         patch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2093\u001b[0m         ),\n\u001b[1;32m   2094\u001b[0m     )\n\u001b[0;32m-> 2096\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m final_pipeline:\n\u001b[1;32m   2097\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/output_parsers/transform.py:50\u001b[0m, in \u001b[0;36mBaseTransformOutputParser.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage]],\n\u001b[1;32m     47\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     49\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[T]:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform, config, run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m     )\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1202\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1200\u001b[0m input_for_tracing, input_for_transform \u001b[38;5;241m=\u001b[39m tee(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;66;03m# Start the input iterator to ensure the input runnable starts before this one\u001b[39;00m\n\u001b[0;32m-> 1202\u001b[0m final_input: Optional[Input] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_for_tracing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1203\u001b[0m final_input_supported \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m final_output: Optional[Output] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:770\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m final: Input\n\u001b[1;32m    768\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28minput\u001b[39m:\n\u001b[1;32m    771\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m got_first_val:\n\u001b[1;32m    772\u001b[0m         final \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:770\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m final: Input\n\u001b[1;32m    768\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28minput\u001b[39m:\n\u001b[1;32m    771\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m got_first_val:\n\u001b[1;32m    772\u001b[0m         final \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/runnables/passthrough.py:497\u001b[0m, in \u001b[0;36mRunnableAssign.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Dict[\u001b[38;5;28mstr\u001b[39m, Any]],\n\u001b[1;32m    494\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    496\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m--> 497\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    499\u001b[0m     )\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1226\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1225\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1226\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   1228\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/runnables/passthrough.py:487\u001b[0m, in \u001b[0;36mRunnableAssign._transform\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m filtered\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# yield map output\u001b[39;00m\n\u001b[0;32m--> 487\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m cast(Dict[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[43mfirst_map_chunk_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m map_output:\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2440\u001b[0m, in \u001b[0;36mRunnableParallel.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   2435\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2436\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   2437\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2438\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   2439\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m-> 2440\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[1;32m   2441\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   2442\u001b[0m     )\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1226\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1225\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1226\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   1228\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2425\u001b[0m, in \u001b[0;36mRunnableParallel._transform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2423\u001b[0m (step_name, generator) \u001b[38;5;241m=\u001b[39m futures\u001b[38;5;241m.\u001b[39mpop(future)\n\u001b[1;32m   2424\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2425\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m AddableDict({step_name: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m})\n\u001b[1;32m   2426\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   2427\u001b[0m     futures[executor\u001b[38;5;241m.\u001b[39msubmit(\u001b[38;5;28mnext\u001b[39m, generator)] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2428\u001b[0m         step_name,\n\u001b[1;32m   2429\u001b[0m         generator,\n\u001b[1;32m   2430\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.13_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2132\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   2127\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2128\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   2129\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2130\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2131\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 2132\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[1;32m   2133\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[1;32m   2135\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m   2136\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2137\u001b[0m     )\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1226\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1225\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1226\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   1228\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2096\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[0;34m(self, input, run_manager, config)\u001b[0m\n\u001b[1;32m   2087\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m steps:\n\u001b[1;32m   2088\u001b[0m     final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   2089\u001b[0m         final_pipeline,\n\u001b[1;32m   2090\u001b[0m         patch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2093\u001b[0m         ),\n\u001b[1;32m   2094\u001b[0m     )\n\u001b[0;32m-> 2096\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m final_pipeline:\n\u001b[1;32m   2097\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m output\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:780\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m         final \u001b[38;5;241m=\u001b[39m final \u001b[38;5;241m+\u001b[39m chunk  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[0;32m--> 780\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:575\u001b[0m, in \u001b[0;36mRunnable.stream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m    568\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m    570\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[1;32m    571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;124;03m    Default implementation of stream, which calls invoke.\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03m    Subclasses should override this method if they support streaming output.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/retrievers.py:121\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: \u001b[38;5;28mstr\u001b[39m, config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    119\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    120\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/retrievers.py:223\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    222\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[1;32m    226\u001b[0m         result,\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    228\u001b[0m     )\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_core/retrievers.py:216\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/langchain_community/retrievers/tavily_search_api.py:43\u001b[0m, in \u001b[0;36mTavilySearchAPIRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m     41\u001b[0m tavily \u001b[38;5;241m=\u001b[39m Client(api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;129;01mor\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTAVILY_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     42\u001b[0m max_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_generated_answer \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 43\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mtavily\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_depth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_answer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_generated_answer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_raw_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_raw_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m docs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m     Document(\n\u001b[1;32m     56\u001b[0m         page_content\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     71\u001b[0m ]\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude_generated_answer:\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/tavily/tavily.py:41\u001b[0m, in \u001b[0;36mClient.search\u001b[0;34m(self, query, search_depth, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, search_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbasic\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     38\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    Combined search method. Set search_depth to either \"basic\" or \"advanced\".\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/tavily/tavily.py:30\u001b[0m, in \u001b[0;36mClient._search\u001b[0;34m(self, query, search_depth, max_results, include_domains, exclude_domains, include_answer, include_raw_content, include_images)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mInternal search method to send the request to the API.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: query,\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m: search_depth,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_key\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n\u001b[1;32m     29\u001b[0m }\n\u001b[0;32m---> 30\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/mlops/langchain_obs/.venv/lib/python3.10/site-packages/requests/adapters.py:532\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[0;32m--> 532\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='api.tavily.com', port=443): Read timed out. (read timeout=100)"
     ]
    }
   ],
   "source": [
    "for s in parallel_chain.stream({\"question\": \"what is langsmith\"}):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a749099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'simple_answer': ''}\n",
      "{'simple_answer': 'I'}\n",
      "{'simple_answer': \"I'm\"}\n",
      "{'simple_answer': \"I'm sorry\"}\n",
      "{'simple_answer': \"I'm sorry,\"}\n",
      "{'simple_answer': \"I'm sorry, but\"}\n",
      "{'simple_answer': \"I'm sorry, but I\"}\n",
      "{'simple_answer': \"I'm sorry, but I couldn\"}\n",
      "{'simple_answer': \"I'm sorry, but I couldn't\"}\n",
      "{'simple_answer': \"I'm sorry, but I couldn't find\"}\n",
      "{'simple_answer': \"I'm sorry, but I couldn't find any\"}\n",
      "{'simple_answer': \"I'm sorry, but I couldn't find any information\"}\n",
      "{'simple_answer': \"I'm sorry, but I couldn't find any information on\"}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Lang'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\"'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a miss'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a missp'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term.'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': ''}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'Lang'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents.'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug,'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test,'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate,'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any L'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework.'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. Lang'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with Lang'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain,'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with L'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLM'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs.'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform for'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform for tracking'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform for tracking system'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform for tracking system-level'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform for tracking system-level and'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform for tracking system-level and model'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform for tracking system-level and model/'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform for tracking system-level and model/chain'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform for tracking system-level and model/chain performance'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform for tracking system-level and model/chain performance,'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform for tracking system-level and model/chain performance, debugging'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform for tracking system-level and model/chain performance, debugging issues'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform for tracking system-level and model/chain performance, debugging issues,'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform for tracking system-level and model/chain performance, debugging issues, and'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform for tracking system-level and model/chain performance, debugging issues, and understanding'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform for tracking system-level and model/chain performance, debugging issues, and understanding user'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform for tracking system-level and model/chain performance, debugging issues, and understanding user interactions'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform for tracking system-level and model/chain performance, debugging issues, and understanding user interactions with'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform for tracking system-level and model/chain performance, debugging issues, and understanding user interactions with applications'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform for tracking system-level and model/chain performance, debugging issues, and understanding user interactions with applications.'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"Langsmith.\" It might be a misspelling or a less-known term. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs. It also provides a unified platform for tracking system-level and model/chain performance, debugging issues, and understanding user interactions with applications.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs,'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement,'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing,'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and version'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning of'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning of prompts'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning of prompts.'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning of prompts. Lang'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning of prompts. LangSmith'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning of prompts. LangSmith also'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning of prompts. LangSmith also provides'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning of prompts. LangSmith also provides tools'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning of prompts. LangSmith also provides tools for'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning of prompts. LangSmith also provides tools for dataset'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning of prompts. LangSmith also provides tools for dataset c'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning of prompts. LangSmith also provides tools for dataset curation'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning of prompts. LangSmith also provides tools for dataset curation,'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning of prompts. LangSmith also provides tools for dataset curation, performance'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning of prompts. LangSmith also provides tools for dataset curation, performance monitoring'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning of prompts. LangSmith also provides tools for dataset curation, performance monitoring,'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning of prompts. LangSmith also provides tools for dataset curation, performance monitoring, and'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning of prompts. LangSmith also provides tools for dataset curation, performance monitoring, and feedback'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning of prompts. LangSmith also provides tools for dataset curation, performance monitoring, and feedback collection'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning of prompts. LangSmith also provides tools for dataset curation, performance monitoring, and feedback collection.'}\n",
      "{'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It seems to be a term that is not widely recognized or used. Could you please provide more context or clarify your question?', 'retrieved_answer': 'LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps users trace and evaluate their language model applications and intelligent agents, providing visibility into model inputs and outputs, and allowing for the refinement, testing, and versioning of prompts. LangSmith also provides tools for dataset curation, performance monitoring, and feedback collection.'}\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "for s in parallel_chain.stream({\"question\": \"what is langsmith\"}):\n",
    "    for k,v in s.items():\n",
    "        if k not in result:\n",
    "            result[k] = \"\"\n",
    "        result[k] += v\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6b5174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
